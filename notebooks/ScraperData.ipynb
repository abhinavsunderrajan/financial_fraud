{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4586a782-bb17-4ab7-8671-0e091e426ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pyperclip\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "from glob import glob\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "from crewai_tools import ScrapeWebsiteTool\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import xml.etree.ElementTree as ET\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(nb_workers = 16, progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3aac78-4e88-430c-b754-5c9076bfbbcd",
   "metadata": {},
   "source": [
    "## MAS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eaaf70-00fe-46c5-b86a-bcbe533f8e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "website = 'https://www.mas.gov.sg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965b5173-d949-4be3-8e15-70d5d4797122",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.mas.gov.sg/regulation/enforcement/enforcement-actions/?page=1&q=&sort=&rows=All#MasXbeEnforcementActionKeyword'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "}\n",
    "response = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb08b9f-5c62-419e-a7b8-5a63699749e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb8759e-2a95-4fb6-992e-f3ff60b8e094",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find_all('table')\n",
    "\n",
    "# Extract headers\n",
    "headers = [header.get_text(strip=True) for header in table[0].find_all('th')]\n",
    "headers.append('url_link')\n",
    "\n",
    "# Extract rows\n",
    "rows = []\n",
    "for row in table[0].find_all('tr')[1:]:  # Skip the header row\n",
    "    cells = row.find_all('td')\n",
    "    row_data = []\n",
    "    for cell in cells:\n",
    "        row_data.append(cell.get_text(strip=True))\n",
    "        if cell.find('a', href=True) is not None:\n",
    "            row_data.append(cell.find('a', href=True) ['href'])\n",
    "    rows.append(row_data)\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df = pd.DataFrame(rows, columns=headers)\n",
    "df[\"url_link\"] = df[\"url_link\"].apply(lambda x: f\"{website}{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1c22da-d2ac-48cc-a203-b251c33038e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_mass_offenses(url):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "    text = re.sub(r'\\n+', '\\n', text.strip(\"\\t\"))\n",
    "    return re.sub(r' +', ' ', text.strip(\"\\t\")).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cbadac-f793-48bb-92dc-0ecf29d0c4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"economic_offense\"] = df.parallel_apply(lambda row: get_all_mass_offenses(row['url_link']), axis=1)\n",
    "df.to_csv(\"mas_enforcement_actions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41bc761-39c7-440d-9a6e-d5a4ead90930",
   "metadata": {},
   "source": [
    "## UNSC sanctioned list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eeeecb-cb11-4507-8bdc-8ff4787bf865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and parse the XML file\n",
    "file_path = \"consolidated_unsc.xml\"  # Change this to your file path\n",
    "tree = ET.parse(file_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Extract all individuals\n",
    "individuals = []\n",
    "for individual in root.findall('.//INDIVIDUAL'):\n",
    "    data = {\n",
    "        \"DATAID\": individual.findtext(\"DATAID\", \"\"),\n",
    "        \"VERSIONNUM\": individual.findtext(\"VERSIONNUM\", \"\"),\n",
    "        \"FIRST_NAME\": individual.findtext(\"FIRST_NAME\", \"\"),\n",
    "        \"SECOND_NAME\": individual.findtext(\"SECOND_NAME\", \"\"),\n",
    "        \"THIRD_NAME\": individual.findtext(\"THIRD_NAME\", \"\"),\n",
    "        \"FOURTH_NAME\": individual.findtext(\"FOURTH_NAME\", \"\"),\n",
    "        \"UN_LIST_TYPE\": individual.findtext(\"UN_LIST_TYPE\", \"\"),\n",
    "        \"REFERENCE_NUMBER\": individual.findtext(\"REFERENCE_NUMBER\", \"\"),\n",
    "        \"LISTED_ON\": individual.findtext(\"LISTED_ON\", \"\"),\n",
    "        \"NAME_ORIGINAL_SCRIPT\": individual.findtext(\"NAME_ORIGINAL_SCRIPT\", \"\"),\n",
    "        \"COMMENTS1\": individual.findtext(\"COMMENTS1\", \"\"),\n",
    "        \"NATIONALITY\": \", \".join([n.text for n in individual.findall(\"NATIONALITY/VALUE\") if n.text]),\n",
    "        \"LIST_TYPE\": \", \".join([l.text for l in individual.findall(\"LIST_TYPE/VALUE\") if l.text]),\n",
    "        \"DATE_OF_BIRTH\": individual.findtext(\"INDIVIDUAL_DATE_OF_BIRTH/YEAR\", \"\"),\n",
    "        \"PLACE_OF_BIRTH\": individual.findtext(\"INDIVIDUAL_PLACE_OF_BIRTH/CITY\", \"\") + \", \" +\n",
    "                          individual.findtext(\"INDIVIDUAL_PLACE_OF_BIRTH/STATE_PROVINCE\", \"\") + \", \" +\n",
    "                          individual.findtext(\"INDIVIDUAL_PLACE_OF_BIRTH/COUNTRY\", \"\"),\n",
    "    }\n",
    "    individuals.append(data)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(individuals)\n",
    "df.to_csv(\"./csv/unsc_sanctioned_individuals.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fab199-3621-42e6-b457-19e6c32be043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "\n",
    "# Load and parse the XML file\n",
    "file_path = \"consolidated_unsc.xml\"  # Change this to your file path\n",
    "tree = ET.parse(file_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Extract all entities\n",
    "entities = []\n",
    "for entity in root.findall('.//ENTITY'):\n",
    "    data = {\n",
    "        \"DATAID\": entity.findtext(\"DATAID\", \"\"),\n",
    "        \"VERSIONNUM\": entity.findtext(\"VERSIONNUM\", \"\"),\n",
    "        \"FIRST_NAME\": entity.findtext(\"FIRST_NAME\", \"\"),\n",
    "        \"SECOND_NAME\": entity.findtext(\"SECOND_NAME\", \"\"),\n",
    "        \"THIRD_NAME\": entity.findtext(\"THIRD_NAME\", \"\"),\n",
    "        \"FOURTH_NAME\": entity.findtext(\"FOURTH_NAME\", \"\"),\n",
    "        \"UN_LIST_TYPE\": entity.findtext(\"UN_LIST_TYPE\", \"\"),\n",
    "        \"REFERENCE_NUMBER\": entity.findtext(\"REFERENCE_NUMBER\", \"\"),\n",
    "        \"LISTED_ON\": entity.findtext(\"LISTED_ON\", \"\"),\n",
    "        \"NAME_ORIGINAL_SCRIPT\": entity.findtext(\"NAME_ORIGINAL_SCRIPT\", \"\"),\n",
    "        \"COMMENTS1\": entity.findtext(\"COMMENTS1\", \"\"),\n",
    "        \"NATIONALITY\": \", \".join([n.text for n in entity.findall(\"NATIONALITY/VALUE\") if n.text]),\n",
    "        \"LIST_TYPE\": \", \".join([l.text for l in entity.findall(\"LIST_TYPE/VALUE\") if l.text]),\n",
    "    }\n",
    "    entities.append(data)\n",
    "\n",
    "# Create DataFrame for entities\n",
    "df_entities = pd.DataFrame(entities)\n",
    "# Save to CSV if needed\n",
    "df_entities.to_csv(\"./csv/unsc_sanctioned_individuals_entities.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdaf9e8-4119-40d8-8451-bbcdffb4baf2",
   "metadata": {},
   "source": [
    "## OFAC list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9e6263-7b7e-45a2-9d6a-3eab1fe5094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./csv/sdn.xml\"  # Replace with your actual file path\n",
    "tree = ET.parse(file_path)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Define the namespace (from the provided XML file)\n",
    "namespace = {'ns': 'https://sanctionslistservice.ofac.treas.gov/api/PublicationPreview/exports/XML'}\n",
    "\n",
    "# Extract all sdnEntry elements\n",
    "sdn_entries = []\n",
    "for entry in root.findall('{https://sanctionslistservice.ofac.treas.gov/api/PublicationPreview/exports/XML}sdnEntry'):\n",
    "    data = {\n",
    "        \"UID\": entry.findtext(\"{https://sanctionslistservice.ofac.treas.gov/api/PublicationPreview/exports/XML}uid\", \"\"),\n",
    "        \"LAST_NAME\": entry.findtext(\"{https://sanctionslistservice.ofac.treas.gov/api/PublicationPreview/exports/XML}lastName\", \"\"),\n",
    "        \"SDN_TYPE\": entry.findtext(\"{https://sanctionslistservice.ofac.treas.gov/api/PublicationPreview/exports/XML}sdnType\", \"\"),\n",
    "        \"PROGRAMS\": \", \".join([p.text for p in entry.findall(\"{https://sanctionslistservice.ofac.treas.gov/api/PublicationPreview/exports/XML}programList/{https://sanctionslistservice.ofac.treas.gov/api/PublicationPreview/exports/XML}program\") if p.text]),\n",
    "        \"AKA_LIST\": \"; \".join(\n",
    "            [f\"{aka.findtext('{https://sanctionslistservice.ofac.treas.gov/api/PublicationPreview/exports/XML}type', '')} ({aka.findtext('{https://sanctionslistservice.ofac.treas.gov/api/PublicationPreview/exports/XML}category', '')}): {aka.findtext('{https://sanctionslistservice.ofac.treas.gov/api/PublicationPreview/exports/XML}lastName', '')}\"\n",
    "             for aka in entry.findall(\"{https://sanctionslistservice.ofac.treas.gov/api/PublicationPreview/exports/XML}akaList/{https://sanctionslistservice.ofac.treas.gov/api/PublicationPreview/exports/XML}aka\")]\n",
    "        ),\n",
    "        \"ADDRESSES\": \"; \".join(\n",
    "            [f\"{addr.findtext('{https://sanctionslistservice.ofac.treas.gov/api/PublicationPreview/exports/XML}address1', '')}, {addr.findtext('{https://sanctionslistservice.ofac.treas.gov/api/PublicationPreview/exports/XML}city', '')}, {addr.findtext('{https://sanctionslistservice.ofac.treas.gov/api/PublicationPreview/exports/XML}postalCode', '')}, {addr.findtext('{https://sanctionslistservice.ofac.treas.gov/api/PublicationPreview/exports/XML}country', '')}\"\n",
    "             for addr in entry.findall(\"{https://sanctionslistservice.ofac.treas.gov/api/PublicationPreview/exports/XML}addressList/{https://sanctionslistservice.ofac.treas.gov/api/PublicationPreview/exports/XML}address\")]\n",
    "        ),\n",
    "    }\n",
    "    sdn_entries.append(data)\n",
    "\n",
    "# Create DataFrame for sdnEntry elements\n",
    "df_sdn_entries = pd.DataFrame(sdn_entries)\n",
    "df_sdn_entries.to_csv(\"./csv/ofac_list.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6177ee1b-b3d6-4bdc-ab61-12bf20cb1234",
   "metadata": {},
   "source": [
    "## Interpol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b74918-b2af-418f-9559-3a5193c5be48",
   "metadata": {},
   "outputs": [],
   "source": [
    "inidviduals = pd.read_csv(\"./csv/interpol_1.csv\")\n",
    "# json.loads(\"./csv/interpol_2.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b131b73-f922-4802-aa7f-803c6ee8630d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(inidviduals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26349ad-f6d5-4157-a43f-3f7c40e65400",
   "metadata": {},
   "source": [
    "## SEC data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8902ea4b-be7c-43a6-a09d-5e7255c369c0",
   "metadata": {},
   "source": [
    "### Get all the litigations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e97c37c-4c1c-4a95-be33-efeede1d0c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from crewai_tools import ScrapeWebsiteTool\n",
    "\n",
    "# # To enable scrapping any website it finds during it's execution\n",
    "# tool = ScrapeWebsiteTool()\n",
    "\n",
    "# # Initialize the tool with the website URL, \n",
    "# # so the agent can only scrap the content of the specified website\n",
    "# tool = ScrapeWebsiteTool(website_url='https://www.sec.gov/enforcement-litigation/litigation-releases/lr-26233')\n",
    "\n",
    "# # Extract the text from the site\n",
    "# text = tool.run()\n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedebaa1-7fb5-491b-9900-b9f69db64e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Configure Selenium with Chrome (Headless Mode)\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no UI)\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "chrome_options.add_argument(\"start-maximized\")\n",
    "chrome_options.add_argument(\"disable-infobars\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36\")\n",
    "\n",
    "# chrome_options.add_argument(\"--headless\")  # Run without GUI\n",
    "# chrome_options.add_argument(\"--disable-gpu\")\n",
    "# chrome_options.add_argument(\"--no-sandbox\")\n",
    "# chrome_options.add_argument(\"--disable-dev-shm-usage\")  \n",
    "# chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")  # Prevent detection\n",
    "# chrome_options.add_argument(\"--disable-extensions\")\n",
    "# chrome_options.add_argument(\"--disable-infobars\")\n",
    "# chrome_options.add_argument(\"--disable-popup-blocking\")\n",
    "# chrome_options.add_argument(\"--disable-background-networking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "042a2da1-5bf2-4a66-9f31-82224630e494",
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_year_month = pd.DataFrame({\"year\" : list(range(1996, 2026))})\n",
    "sec_year_month[\"month\"] = [list(range(1, 13)) for i in range(len(sec_year_month))]\n",
    "sec_year_month = sec_year_month.explode(\"month\")\n",
    "sec_year_month.reset_index(inplace=True, drop=True)\n",
    "sec_year_month[\"page_url\"] = sec_year_month.apply(lambda row: f\"https://www.sec.gov/enforcement-litigation/litigation-releases?populate=&year={row['year']}&month={row['month']}\", axis=1)\n",
    "sec_year_month = sec_year_month.iloc[:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10795baf-8757-4082-b04e-6082802ae9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>page_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.sec.gov/enforcement-litigation/litigation-releases?populate=&amp;year=2024&amp;month=5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>https://www.sec.gov/enforcement-litigation/litigation-releases?populate=&amp;year=2024&amp;month=6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>2024</td>\n",
       "      <td>7</td>\n",
       "      <td>https://www.sec.gov/enforcement-litigation/litigation-releases?populate=&amp;year=2024&amp;month=7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>2024</td>\n",
       "      <td>8</td>\n",
       "      <td>https://www.sec.gov/enforcement-litigation/litigation-releases?populate=&amp;year=2024&amp;month=8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>https://www.sec.gov/enforcement-litigation/litigation-releases?populate=&amp;year=2024&amp;month=9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>https://www.sec.gov/enforcement-litigation/litigation-releases?populate=&amp;year=2024&amp;month=10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>https://www.sec.gov/enforcement-litigation/litigation-releases?populate=&amp;year=2024&amp;month=11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>https://www.sec.gov/enforcement-litigation/litigation-releases?populate=&amp;year=2024&amp;month=12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>2025</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.sec.gov/enforcement-litigation/litigation-releases?populate=&amp;year=2025&amp;month=1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>2025</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.sec.gov/enforcement-litigation/litigation-releases?populate=&amp;year=2025&amp;month=2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     year month  \\\n",
       "340  2024     5   \n",
       "341  2024     6   \n",
       "342  2024     7   \n",
       "343  2024     8   \n",
       "344  2024     9   \n",
       "345  2024    10   \n",
       "346  2024    11   \n",
       "347  2024    12   \n",
       "348  2025     1   \n",
       "349  2025     2   \n",
       "\n",
       "                                                                                        page_url  \n",
       "340   https://www.sec.gov/enforcement-litigation/litigation-releases?populate=&year=2024&month=5  \n",
       "341   https://www.sec.gov/enforcement-litigation/litigation-releases?populate=&year=2024&month=6  \n",
       "342   https://www.sec.gov/enforcement-litigation/litigation-releases?populate=&year=2024&month=7  \n",
       "343   https://www.sec.gov/enforcement-litigation/litigation-releases?populate=&year=2024&month=8  \n",
       "344   https://www.sec.gov/enforcement-litigation/litigation-releases?populate=&year=2024&month=9  \n",
       "345  https://www.sec.gov/enforcement-litigation/litigation-releases?populate=&year=2024&month=10  \n",
       "346  https://www.sec.gov/enforcement-litigation/litigation-releases?populate=&year=2024&month=11  \n",
       "347  https://www.sec.gov/enforcement-litigation/litigation-releases?populate=&year=2024&month=12  \n",
       "348   https://www.sec.gov/enforcement-litigation/litigation-releases?populate=&year=2025&month=1  \n",
       "349   https://www.sec.gov/enforcement-litigation/litigation-releases?populate=&year=2025&month=2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None);\n",
    "sec_year_month.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c0d81b-f547-4638-8b4b-2028f5e21632",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Service(ChromeDriverManager().install())\n",
    "def get_page_details(url):\n",
    "    base_name = url.split(\"populate=\")[-1].replace(\"&\", \"_\").replace(\"=\", \"_\")\n",
    "    file_path = f\"./sec_data/sec_data{base_name}.csv\"\n",
    "    if os.path.exists(file_path):\n",
    "        # print(f\"Finished {url}\")\n",
    "        return\n",
    "\n",
    "    \n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    driver.get(url)\n",
    "    time.sleep(1)  # Allow time for page to load\n",
    "    \n",
    "    # Find the table containing litigation releases\n",
    "    try:\n",
    "        table = driver.find_element(By.TAG_NAME, \"table\")\n",
    "        rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "        \n",
    "        # Extract headers\n",
    "        headers = [th.text.strip() for th in rows[0].find_elements(By.TAG_NAME, \"th\")]\n",
    "    \n",
    "        # Extract data from rows\n",
    "        data = []\n",
    "        for row in rows[1:]:  # Skip header row\n",
    "            cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "            row_data = [col.text.strip() for col in cols]\n",
    "            # Extract hyperlink from the first column (if present)\n",
    "            # print(cols[1].text)\n",
    "            links = cols[1].find_elements(By.TAG_NAME, \"a\")\n",
    "            links = [link.get_attribute(\"href\") for link in links]\n",
    "            \n",
    "    \n",
    "            row_data.append(links)  # Add link as the last column\n",
    "            data.append(row_data)\n",
    "    \n",
    "        # Append \"Link\" column to headers\n",
    "        headers.append(\"Link\")\n",
    "    \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(data, columns=headers)\n",
    "        df.to_csv(file_path, index=False)\n",
    "        driver.quit()\n",
    "        print(f\"Completed file of {len(df)} for {url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error scraping table for:  {url}\")\n",
    "        driver.quit()\n",
    "        \n",
    "    \n",
    "sec_year_month.apply(lambda row: get_page_details(row['page_url']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b6001e-c534-431f-b62d-3406e5813777",
   "metadata": {},
   "source": [
    "### Get details of all the litigations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed0f305-8f85-4da6-be78-47445888d5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11464\n"
     ]
    }
   ],
   "source": [
    "all_lits = [pd.read_csv(file) for file in glob(\"./sec_data/*csv\")]\n",
    "all_lits_sec = pd.concat(all_lits, ignore_index=True)\n",
    "print(len(all_lits_sec))\n",
    "all_lits_sec[\"year\"] = all_lits_sec[\"Date\\nSort descending\"].apply(lambda x: int(x.split(',')[1].strip()))\n",
    "all_lits_sec = all_lits_sec.sort_values(by=[\"year\"], ascending=False)\n",
    "all_lits_sec.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600b4324-4125-417a-addb-3cf3a7d33b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "for index_, row in tqdm(all_lits_sec.iterrows()):\n",
    "    try:\n",
    "        respondents = row[\"Respondents\"].replace('\\n', ' ')\n",
    "        respondents = respondents.translate(str.maketrans('', '', string.punctuation))\n",
    "        links = row[\"Link\"]\n",
    "        date = row[\"Date\\nSort descending\"]\n",
    "        links = ast.literal_eval(links)\n",
    "        # print(links, type(links))\n",
    "        \n",
    "        for i, link in enumerate(links):\n",
    "            file_name = f\"./sec_text/{date}_{respondents.split(',')[0][:15]}_link_{i}.txt\"\n",
    "            if os.path.exists(file_name) or \".pdf\" in link:\n",
    "                continue\n",
    "            driver.get(link)\n",
    "            # time.sleep(1)  # Allow time for page to load   \n",
    "            title = driver.title.strip()\n",
    "            # Extract full page content\n",
    "            full_content = driver.find_element(\"tag name\", \"body\").text.strip()\n",
    "            f = open(file_name, \"a\")\n",
    "            f.write(full_content)\n",
    "            f.close()\n",
    "    except Exception as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e585f03-d0f2-4a4f-ab63-09bc316a9fa0",
   "metadata": {},
   "source": [
    "### FCA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdd5966-4e7d-4d0b-9f09-323ada1c5d87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "774cd6bc-fd7f-404c-80d4-02d3dc9ebc93",
   "metadata": {},
   "source": [
    "## Fiancial times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4086465-7f42-457d-9f75-9b8a6dc66a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Service(ChromeDriverManager().install())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3618c4-7b06-41cf-96a8-195706f0986a",
   "metadata": {},
   "source": [
    "### Reuters data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d5ca38-f48e-4d02-9181-3f88777b9351",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Set up the Selenium WebDriver (e.g., using Chrome)\n",
    "driver = webdriver.Chrome()  # Ensure the ChromeDriver is in your PATH\n",
    "query = \"bribery and corruption\"\n",
    "# Extract and print the text and URLs\n",
    "link_text_ls = []\n",
    "link_url_ls = []\n",
    "\n",
    "try:\n",
    "    # Open the Reuters search page\n",
    "    url = f\"https://www.reuters.com/site-search/?query={query.replace(' ','+')}\"\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Wait for elements to be present\n",
    "    elements = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_all_elements_located((By.CSS_SELECTOR, '[data-testid=\"TitleLink\"]'))\n",
    "    )\n",
    "    \n",
    "    \n",
    "    for element in elements:\n",
    "        link_text = element.get_attribute('aria-label')\n",
    "        link_url = element.get_attribute('href')\n",
    "        # print(f\"Link Text: {element.text}\")\n",
    "        # print(f\"Link URL: {link_url}\")\n",
    "        link_text_ls.append(element.text)\n",
    "        link_url_ls.append(link_url)\n",
    "\n",
    "    driver.quit()\n",
    "    for page in range(2, 5):\n",
    "        # Wait for the \"Next\" button to be present and clickable\n",
    "        print(\"click next button\")\n",
    "        time.sleep(random.uniform(2, 5))\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(f\"{url}&offset={page*10}\")\n",
    "\n",
    "       # Optionally, wait for the page to load and perform further actions\n",
    "        # For example, wait for new page content to load\n",
    "        elements = WebDriverWait(driver, 15).until(\n",
    "            EC.presence_of_all_elements_located((By.CSS_SELECTOR, '[data-testid=\"TitleLink\"]'))\n",
    "        )\n",
    "        print(len(elements))\n",
    "\n",
    "        for element in elements:\n",
    "            link_text = element.get_attribute('aria-label')\n",
    "            link_url = element.get_attribute('href')\n",
    "            link_text_ls.append(element.text)\n",
    "            link_url_ls.append(link_url)\n",
    "\n",
    "        \n",
    "finally:\n",
    "    # Close the browser\n",
    "    driver.quit()\n",
    "\n",
    "if len(link_text_ls)>0:\n",
    "    result_df = pd.DataFrame({\"link_text\":link_text_ls, \"link_url\": link_url_ls})\n",
    "    print(len(result_df))\n",
    "    result_df.to_csv(f\"./csv/reuters_{query}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0bc3b0-9962-4234-8de9-c90536b9e209",
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters_files = glob(\"./csv/reuters_*.csv\")\n",
    "reuters_articles = pd.concat([(pd.read_csv(file)) for file in reuters_files], ignore_index=True)\n",
    "print(len(reuters_articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cf2138-7806-4df7-aa69-dddd283db05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To enable scrapping any website it finds during it's execution\n",
    "tool = ScrapeWebsiteTool()\n",
    "article_text_ls = []\n",
    "\n",
    "for index_, row in tqdm(reuters_articles.iterrows()):\n",
    "\n",
    "    tool = ScrapeWebsiteTool(website_url=row[\"link_url\"])\n",
    "    # Extract the text from the site\n",
    "    text = tool.run()\n",
    "    article_text_ls.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fe7baa-18b4-4dbd-aba1-6e50320dff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters_articles[\"article\"] = article_text_ls\n",
    "reuters_articles.to_csv(\"./csv/all_reuters_scraped.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48898168-8d79-4c44-9b00-502fc4aa0f8c",
   "metadata": {},
   "source": [
    "### New API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dea5190-fb61-4a4e-abc1-d9c5cc1c6203",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsapi_files = glob(\"./csv/query_*.csv\")\n",
    "newsapi_files_articles = pd.concat([(pd.read_csv(file)) for file in newsapi_files], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c505845e-c956-49ec-b455-a69c1602c4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_api_text = []\n",
    "\n",
    "for index_, row in tqdm(newsapi_files_articles.iterrows()):\n",
    "    try:\n",
    "        tool = ScrapeWebsiteTool(website_url=row[\"url\"])\n",
    "        # Extract the text from the site\n",
    "        text = tool.run()\n",
    "        news_api_text.append(text)\n",
    "    except Exception as e: \n",
    "         print(e)\n",
    "         news_api_text.append(\"\")\n",
    "\n",
    "newsapi_files_articles[\"article\"] = news_api_text\n",
    "newsapi_files_articles = newsapi_files_articles.loc[newsapi_files_articles.article.str.len()>0]\n",
    "newsapi_files_articles.to_csv(\"./csv/all_newsapi_scraped.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78ed003-ae0f-4565-b19c-9d148005d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "reuters_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd48a81e-a3cf-4e8b-80ed-812687dbdeb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
